%%
% 引言或背景
% 引言是论文正文的开端，应包括毕业论文选题的背景、目的和意义;对国内外研究现状和相关领域中已有的研究成果的简要评述;介绍本项研究工作研究设想、研究方法或实验设计、理论依据或实验基础;涉及范围和预期结果等。要求言简意赅，注意不要与摘要雷同或成为摘要的注解。
% modifier: 黄俊杰(huangjj27， 349373001dc@gmail.com)
% update date: 2017-04-15
%%
\chapter{绪论}
%定义，过去的研究和现在的研究，意义，与图像分割的不同，going deeper
\label{cha:introduction}
\section{选题背景与意义}

如今时代中，人工智能热潮一波又一波掀起，在人力计算所不能及的领域中大放异彩，例如图像识别、无人驾驶、棋类等策略竞技再到如今的语言大模型ChatGPT等等。各种算法架构五花八门的出现为人工智能学科的发展起到极大的推动作用，其中目前在各个研究领域的新兴都离不开深度学习。深度学习使用神经网络架构来进行学习和预测，它在文本、时间序列还有计算机视觉等领域的成功离不开算法和架构设计上的创新，以及通过利用GPU、计算机集群以及专用软件和硬件所带来的巨大计算能力。

但由于目前智能手机、平板电脑、路由器等等边缘设备的普及，它们的巨大数量和一定的计算能力为深度学习带来了新的机遇和挑战。首先最为突出的两个话题就是隐私保护和数据安全，这些边缘设备能够直接访问敏感数据（用户不愿意共享部分），切能够进行大量的设备上计算。其次，各种边缘设备的容量、功率、数据、可用性、通信、内存等方面存在显著差异，这就对传统机器学习模型的本地训练带来挑战。

因此，对于移动端用户数据隐私和模型更新的问题，提出了联邦学习（Federated Learning）。其核心思想是：保障大数据交换时的信息安全、保护终端数据和个人数据隐私、保证合法合规的前提下，在多参与方或多计算结点之间开展高效率的机器学习。关于联邦学习的起源以及目前研究热点与挑战的更多细节介绍可以参考综述\cite{yang2019federated}。
\label{sec:background}
% What is the problem
% why is it interesting and important
% Why is it hards， why do naive approaches fails
% why hasn't it been solved before
% what are the key components of my approach and results， also include any specific limitations，do not repeat the abstract
%contribution

\section{国内外研究现状和相关工作}
\label{sec:related_work}
联邦学习在国内是从2018年开始兴起的，经过两年多的迅猛发展，技术框架及其应用逐渐走向成熟，涌现了众多的平台和产品，为日后的大规模商用落地打了基础。联邦学习的框架的使用保证了基本的安全隐私，如加入同态加密、安全多方计算和差分隐私等机制来保护安全隐私，但现实中仍然存在安全隐私的泄露问题，以及交互开销和系统、数据的异质性问题等。近年来提出的联邦平均算法FedAvg、FedProx等多种算法框架，都可以用来解决上述问题，并且还能用于优化模型学习的效率，以及提升联邦学习公平性和鲁棒性等。

参考了目前在联邦学习领域主要需要解决的具体问题和面临的挑战可以分为下面的几个种类：

$\cdot$在数据非独立同分布（non-iid)问题中，非独立同分布指的是，数据存储于不同本地位置导致数据分布的不一致性。这会导致网络中出现不同设备的数据分布存在明显差异的情况，例如在输入法自动补全任务中，不同手机用户使用的语言输入法多种多样。由于设备间数据不同，可能存在潜在的统计结构，以反映不同设备之间的关系和分布特点。

$\cdot$通信开销是一个重要问题：在联邦学习（FL）环境中，需要不断更新模型，导致海量设备之间信息交换。由于带宽、能源等限制，网络交互通常比本地计算慢，尤其是在带宽受限或设备众多时更为突出。因此，如何提高交互效率至关重要，需要考虑两个方面：减少每轮交互的信息量或降低交互频率。

$\cdot$系统的异构性在联邦网络中显著体现，因为硬件（如CPU、内存）、网络连接方式（3G、4G、5G、Wi-Fi）、电池电量等方面存在差异，导致每台设备的存储能力可能不同。此外，由于设备上的系统相关限制以及网络规模大小的限制，一般只有少数设备会同时处于活跃状态。例如，在一个拥有100万台设备的网络中，可能只有数百台设备会保持活跃状态。每台设备或许都不可靠，活跃设备在某次迭代中掉线是常见情况，因为有连通性或是能源的限制。这些系统层面的特性加大了挑战，比如滞后者处理和容错。因此，发展和分析联邦学习方法时必须考虑:(i)低参与度的期望，(ii)能接受异构的硬件(iii)对网络中掉线设备的鲁棒性。

$\cdot$统计异质性：设备在网络中生成和搜集数据的方式通常不是同分布的，比如，移动电话用户在语言使用上有差异，给下一个单词预测任务带来背景。此外，设备间数据点的数量也可能有显著不同。可能存在潜在结构捕获设备及其相关分布关系。这一数据生成模式违反了分布式优化中通常使用的独立同分布方式。
在（I.I.D.）假设下，考虑引入滞后者可能会增加建模、分析和评估的复杂性。尽管典型的联邦学习问题旨在学习单一全局模型，但也存在其他方案，如多任务学习。在这个领域，联邦学习的领先方法与元学习密切相关。多任务学习和元学习都赞同以个性化建模作为处理数据统计异质性的方式会更加自然。

$\cdot$ 最后是关于隐私问题，这也是个需要重点关注的问题。联邦学习采用共享模型更新方式，尽管通过共享梯度信息，能够在一定程度上保护各设备上生成的数据。然而，在模型更新传递的训练过程中，仍存在敏感信息泄露给第三方或中央服务器的风险。近期研究致力于运用安全多方计算或差分隐私等措施来强化联邦学习的隐私性，但这些措施往往以损害模型性能或系统效率为代价。要构建私密联邦学习系统，需要在理论与实践中平衡并理解这些权衡将会是一个相当大的挑战。

针对上述的这些问题，相关研究都给出了一些解决办法，这里简单罗列一下部分案例工作的现状：

$\cdot$ 对于在non-iid数据上联邦学习模型的性能显著下降问题，Zhao, Yue等人在2018年提出\cite{FedAvgOnNon-iid}，可以用权重发散weight divergence来解释性能下降，并且给出指标EMD，用建立一个小的共享数据集，这个共享数据集分布与总体相同，在模型参数初始化后，服务端先在共享数据集上初步训练再去分发到客户端，这样可以降低EMD指标，提高训练结果准确率，从而避免异构数据问题。

$\cdot$ 对于通信开销问题，Su, Xiaoxin等人在2023年提出一种框架——FedLC（Federated Learning With Lossy Communications）\cite{XiaoxinSu2023}，带有丢失通信的联邦学习框架。它针对高丢包情况下网络资源利用率低的情况，使用UDP在客户端和服务器之间数据传输，而且还整合了压缩、前向纠错和自动重传技术，能控制传输的流量和丢包率，可以显著降低在网络不稳定易出现丢失通信的环境下的通信开销，从而提升FL模型的性能。

$\cdot$ 对于统计异质性问题，可以通过两种方法解决：1）在本地分布维护多个全局模型，类似于对所有的本地模型进行聚类，为相近的本地模型保留异质性；2）构建出个性化的联邦模型，整合全局和本地的信息去为每个客户端生成个性化的FL模型，这需要比较高的通信开销，以及对本地模型的依赖。Yue Tan等人在2021年提出FedProto（ Federated Prototype Learning across Heterogeneous Clients）\cite{tan2022fedproto}，让客户端和服务器之间传递抽象的类别原型，而非传统的梯度，首先从客户端汇集各个本地模型，然后再聚合得到一个全局模型，再把这个全局模型回传给客户端来规范本地模型的训练，让本地模型不断接近全局模型，从而避免了因客户端之间本地梯度不对齐导致的异质性问题。

$\cdot$ 对于隐私问题，Miao, Yinbin等人在2022年提出一个利用区块链实现隐私保护的拜占庭鲁棒性联邦学习（PBFL）方案\cite{Miao2022}，结合区块链技术去减轻中心服务器和恶意客户端的影响。其原理就是——利用余弦相似度来判断恶意客户端上传的恶意梯度。然后，采用全同态加密来提供安全的聚合。最后，使用区块链系统来促进透明的流程和法规的实施。这个方案实现了收敛，且被证明可以提供隐私保护，是一个鲁棒而高效的方案。

\section{本文的论文结构与章节安排}

\label{sec:arrangement}

本文一共可以分为五章，各章节内容安排如下：

第一章绪论。简单说明了本文章的选题背景与意义。

第二章为相关工作。对研究所需的前置知识和相关理论进行一定讲解。

第三章为研究方法。介绍研究的思路与方法，以及实验的具体过程和预期结果。

第四章为理论分析。对实验结果数据进行总结和理论分析。

第五章为结论。总结研究的创新点和不足之处，以及未来的展望。
